\relax 
\citation{park2008bayesian}
\citation{carvalho2010horseshoe}
\citation{mitchell1988bayesian,george1993variable}
\citation{shin2021neuronized}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}\protected@file@percent }
\citation{shin2021neuronized}
\citation{mitchell1988bayesian,george1993variable}
\@writefile{toc}{\contentsline {section}{\numberline {2}Neuronized prior}{2}\protected@file@percent }
\newlabel{sec:neu_def}{{2}{2}}
\newlabel{eq:neuronized}{{1}{2}}
\newlabel{eq:post_joint}{{2}{2}}
\citation{scott2010bayes}
\@writefile{toc}{\contentsline {section}{\numberline {3}Neuronization of Standard Sparse Priors}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1} Discrete and Continuous SpSL Priors}{3}\protected@file@percent }
\citation{castillo2012needles}
\citation{castillo2015bayesian}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Histogram of $T(\alpha )$, $T(\alpha )w$, and the standard SpSL prior.\relax }}{4}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:SpSL_prior}{{1}{4}}
\newlabel{eq:spsl_hyper_beta}{{5}{4}}
\citation{park2008bayesian}
\citation{tibshirani1996regression}
\citation{chen2011bayesian}
\citation{hoff2017lasso}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Bayesian Lasso}{5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Horseshoe, Cauchy and Their Generalization}{5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Histogram of $T(\alpha )$, $T(\alpha )w$, and the standard Horseshoe prior.\relax }}{6}\protected@file@percent }
\newlabel{fig:HS_prior}{{2}{6}}
\citation{shin2021neuronized}
\citation{k1996the}
\citation{s1983optimization}
\@writefile{toc}{\contentsline {section}{\numberline {4}Managing Neuronized Priors }{7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Find the Activation Function to Match a Given Prior}{7}\protected@file@percent }
\citation{shin2021neuronized}
\citation{bhattacharya2016fast}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Choosing Hyper-Parameters}{8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Sampling and Optimization With Neuronized Priors}{8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}MCMC Sampling with Neuronized Priors}{8}\protected@file@percent }
\newlabel{eq:w_condi}{{15}{8}}
\newlabel{eq:log-target}{{16}{8}}
\citation{shin2021neuronized}
\citation{shin2021neuronized}
\citation{liu2000generalised}
\citation{shin2021neuronized}
\newlabel{eq:w_j_sample}{{17}{9}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces A general MCMC algorithm for neuronized priors\relax }}{9}\protected@file@percent }
\newlabel{alg:neu_MCMC}{{1}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Sample $\alpha _0$ efficiently}{9}\protected@file@percent }
\newlabel{sec:samp_alpha0}{{5.2}{9}}
\citation{shin2021neuronized}
\citation{rovckova2014emvs}
\citation{rovckova2018spike}
\citation{shin2021neuronized}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Computational advantage of neuronized discrete SpSL}{10}\protected@file@percent }
\newlabel{sec:neu_dis_spsl_com}{{5.3}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}A Scalable Algorithm for Finding Posterior Modes}{10}\protected@file@percent }
\citation{shin2021neuronized}
\citation{rovckova2014emvs}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces The coordinate-ascent algorithm for neuronized prior (CAAN)\relax }}{11}\protected@file@percent }
\newlabel{alg:caan}{{2}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Comparison With Other Posterior Optimization Procedures}{11}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Trace plots of the log-MSE (top row) and EBIC (bottom row) paths from 10 different initial points for the EMVA and the CAAN optimization algorithms, based on a synthetic dataset generated (n = 120 and p = 200) with the true model 10. \relax }}{12}\protected@file@percent }
\newlabel{fig:Opt_comparison}{{3}{12}}
\citation{shin2021neuronized}
\citation{shin2021neuronized}
\citation{shin2021neuronized}
\citation{ghosh2011rao}
\@writefile{toc}{\contentsline {section}{\numberline {6}Simulation and Real data examples}{13}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Simulation Settings}{13}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Metrics}{14}\protected@file@percent }
\newlabel{sim_metrics}{{6.2}{14}}
\newlabel{mse_computation}{{2}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Simulation results}{15}\protected@file@percent }
\newlabel{simulation_results}{{6.3}{15}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Results for low-dimensional setting (n=200, p=50)\relax }}{15}\protected@file@percent }
\newlabel{table:low1}{{1}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Real data examples}{15}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Results for low-dimensional setting (n=400, p=100)\relax }}{16}\protected@file@percent }
\newlabel{table:low2}{{2}{16}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.4.1}Datasets}{16}\protected@file@percent }
\newlabel{real_world_datasets}{{6.4.1}{16}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.4.2}Evaluation}{16}\protected@file@percent }
\newlabel{real_world_eval}{{6.4.2}{16}}
\citation{shin2021neuronized}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Results for high-dimensional setting (n=100, p=300)\relax }}{17}\protected@file@percent }
\newlabel{table:high1}{{3}{17}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.4.3}Discussion}{17}\protected@file@percent }
\newlabel{real_world_discuss}{{6.4.3}{17}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Results for high-dimensional setting (n=150, p=1000)\relax }}{18}\protected@file@percent }
\newlabel{table:high2}{{4}{18}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusion}{18}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8}Chris Crabtree (My Own) - Contribution}{18}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Results for Boston housing dataset\relax }}{19}\protected@file@percent }
\newlabel{table:boston}{{5}{19}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Results for Bardet-Biedl dataset\relax }}{19}\protected@file@percent }
\newlabel{table:bardet}{{6}{19}}
\@writefile{toc}{\contentsline {section}{\numberline {9}Yunshan Duan - Contribution}{19}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10}Lanxin Yang - Contribution}{20}\protected@file@percent }
\bibstyle{plainnat}
\bibdata{refs}
\bibcite{bhattacharya2016fast}{{1}{2016}{{Bhattacharya et~al.}}{{Bhattacharya, Chakraborty, and Mallick}}}
\bibcite{carvalho2010horseshoe}{{2}{2010}{{Carvalho et~al.}}{{Carvalho, Polson, and Scott}}}
\bibcite{castillo2012needles}{{3}{2012}{{Castillo and van~der Vaart}}{{}}}
\bibcite{castillo2015bayesian}{{4}{2015}{{Castillo et~al.}}{{Castillo, Schmidt-Hieber, and Van~der Vaart}}}
\bibcite{chen2011bayesian}{{5}{2011}{{Chen et~al.}}{{Chen, Wang, and McKeown}}}
\bibcite{george1993variable}{{6}{1993}{{George and McCulloch}}{{}}}
\bibcite{ghosh2011rao}{{7}{2011}{{Ghosh and Clyde}}{{}}}
\bibcite{hoff2017lasso}{{8}{2017}{{Hoff}}{{}}}
\bibcite{s1983optimization}{{9}{1983}{{Kirkpatrick et~al.}}{{Kirkpatrick, Gelatt, and Vecchi}}}
\bibcite{liu2000generalised}{{10}{2000}{{Liu and Sabatti}}{{}}}
\bibcite{k1996the}{{11}{1996}{{Mengersen and Tweedie}}{{}}}
\bibcite{mitchell1988bayesian}{{12}{1988}{{Mitchell and Beauchamp}}{{}}}
\bibcite{park2008bayesian}{{13}{2008}{{Park and Casella}}{{}}}
\bibcite{rovckova2014emvs}{{14}{2014}{{Ro{\v {c}}kov{\'a} and George}}{{}}}
\bibcite{rovckova2018spike}{{15}{2018}{{Ro{\v {c}}kov{\'a} and George}}{{}}}
\bibcite{scott2010bayes}{{16}{2010}{{Scott and Berger}}{{}}}
\bibcite{shin2021neuronized}{{17}{2021}{{Shin and Liu}}{{}}}
\bibcite{tibshirani1996regression}{{18}{1996}{{Tibshirani}}{{}}}
